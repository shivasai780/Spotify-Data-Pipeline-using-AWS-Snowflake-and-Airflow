{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: 0de4aacb-5822-48df-938e-2c1614357e54\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\nWaiting for session 0de4aacb-5822-48df-938e-2c1614357e54 to get into ready status...\nSession 0de4aacb-5822-48df-938e-2c1614357e54 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "s3_path=\"s3://spotify-etl-project-shivasai/raw_data/to_processed/\"",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import explode, col,to_date\nfrom datetime import datetime\nfrom awsglue.dynamicframe import DynamicFrame",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 63,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "source_dyf=glueContext.create_dynamic_frame.from_options( \n    connection_type=\"s3\", \n    connection_options={\"paths\": [s3_path]}, \n    format=\"json\")\n#This is how we will read the json file in this bucket",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spotify_df=source_dyf.toDF()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def process_album(df):\n    #This is For Album\n    df=df.withColumn(\"items\", explode(\"items\")).select(col(\"items.track.album.id\").alias(\"album_id\"),\n                                                            col(\"items.track.album.name\").alias(\"album_name\"),\n                                                          col(\"items.track.album.release_date\").alias(\"release_date\"),\n                                                          col(\"items.track.album.total_tracks\").alias(\"total_tracks\"),\n                                                          col(\"items.track.album.external_urls.spotify\").alias(\"album_url\")\n                                                      ).dropDuplicates(['album_id'])\n    return df\n\ndef process_artist(df):\n    #This is for artists\n    \n    #Explode the items\n    df_items_exploded=df.select(explode(col(\"items\")).alias(\"item\"))\n    \n    #Explode the artists\n    df_artists_exploded=df_items_exploded.select(explode(col(\"item.track.artists\")).alias(\"artist\"))\n    \n    #Now select the artists\n    df_artists=df_artists_exploded.select(\n        col(\"artist.id\").alias(\"artist_id\"), \n        col(\"artist.name\").alias(\"artist_name\"),\n        col(\"artist.external_urls.spotify\").alias(\"artist_url\")\n    ).dropDuplicates(['artist_id'])\n    \n    return df_artists\n\ndef process_songs(df):\n    #Explode the items array to create a row for each song\n    df_exploded=df.select(explode(col(\"items\")).alias(\"item\"))\n    \n    df_songs=df_exploded.select(\n        col(\"item.track.id\").alias(\"song_id\"), \n        col(\"item.track.name\").alias(\"song_name\"), \n        col(\"item.track.duration_ms\").alias(\"duration_ms\"), \n        col(\"item.track.external_urls.spotify\").alias(\"url\"),\n        col(\"item.track.popularity\").alias(\"popularity\"),\n        col(\"item.added_at\").alias(\"song_added\"),\n        col(\"item.track.album.id\").alias(\"album_id\"),\n        col(\"item.track.artists\")[0][\"id\"].alias(\"artist_id\")\n    ).dropDuplicates(['song_id'])   \n    \n    #convert string dates in 'song added'to actual date types\n    df_songs=df_songs.withColumn(\"song_added\", to_date(col(\"song_added\")))\n    \n    return df_songs\n    \n                                                           \n    ",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 55,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "album_df=process_album(spotify_df)\nartist_df=process_artist(spotify_df)\nsong_df=process_songs(spotify_df)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 58,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "album_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 59,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+--------------------+------------+------------+--------------------+\n|            album_id|          album_name|release_date|total_tracks|           album_url|\n+--------------------+--------------------+------------+------------+--------------------+\n|0DLvFVIfwt3OHdK9k...|Where I've Been, ...|  2024-05-31|          12|https://open.spot...|\n|0EiI8ylL0FmWWpgHV...|The Rise and Fall...|  2023-09-22|          14|https://open.spot...|\n|0Wmt50XH9EZvSuML0...|Neva Play (feat. ...|  2024-09-06|           1|https://open.spot...|\n|10FLjwfpbxLmW8c25...|    Die With A Smile|  2024-08-16|           1|https://open.spot...|\n|15XcLhiVMlSOipUdd...|                MUSE|  2024-07-19|           7|https://open.spot...|\n+--------------------+--------------------+------------+------------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "artist_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 60,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+------------+--------------------+\n|           artist_id| artist_name|          artist_url|\n+--------------------+------------+--------------------+\n|06HL4z0CvFAxyc27G...|Taylor Swift|https://open.spot...|\n|0PCCGZ0wGLizHt2KZ...|     Artemas|https://open.spot...|\n|0Y5tJX1MQlPlqiwlO...|Travis Scott|https://open.spot...|\n|0du5cEVh5yTK9QJze...|  Bruno Mars|https://open.spot...|\n|12GqGscKJx3aE4t07...|  Peso Pluma|https://open.spot...|\n+--------------------+------------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "song_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 61,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+-------------------+-----------+--------------------+----------+----------+--------------------+--------------------+\n|             song_id|          song_name|duration_ms|                 url|popularity|song_added|            album_id|           artist_id|\n+--------------------+-------------------+-----------+--------------------+----------+----------+--------------------+--------------------+\n|0OA00aPt3BV10qeMI...|          Big Dawgs|     190666|https://open.spot...|        93|2024-09-20|6Yw4204wbgmpsGTzj...|4nVa6XlBFlIkF6msW...|\n|0UYnhUfnUj5adChuA...|        Sailor Song|     211978|https://open.spot...|        89|2024-09-20|4DWrYvfGXRE8ko5Zx...|1iCnM8foFssWlPRLf...|\n|0WbMK4wrZ1wFSty9F...|   Good Luck, Babe!|     218423|https://open.spot...|        97|2024-09-20|1WAjjRMfZjEXtB0lQ...|7GlBOeep6PqTfFi59...|\n|0nJW01T7XtvILxQgC...|When I Was Your Man|     213826|https://open.spot...|        89|2024-09-20|58ufpQsJ1DS5kq4hh...|0du5cEVh5yTK9QJze...|\n|17phhZDn6oGtzMe56...|       Lose Control|     210688|https://open.spot...|        91|2024-09-20|7nacKlk586eLRBSIs...|33qOK5uJ8AR2xuQQA...|\n+--------------------+-------------------+-----------+--------------------+----------+----------+--------------------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def write_to_s3(df, path_suffix,format_type=\"csv\"):\n    #From the spark data framewe are creating the Dynamic Frame\n    dynamic_frame=DynamicFrame.fromDF(df, glueContext, \"dynamic_frame\")\n    \n    #Writes the dynamic frame in the specific format\n    glueContext.write_dynamic_frame.from_options(\n        frame=dynamic_frame,\n        connection_type=\"s3\",\n        connection_options={\"path\": f\"s3://spotify-etl-project-shivasai/transformed_data/{path_suffix}/\" },\n        format=format_type \n    )",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 64,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "write_to_s3(album_df, f\"albums_data/album_transformed_{datetime.now().strftime('%Y-%m-%d')}\",\"csv\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 66,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "write_to_s3(artist_df, f\"artists_data/artist_transformed_{datetime.now().strftime('%Y-%m-%d')}\",\"csv\")\nwrite_to_s3(song_df, f\"songs_data/songs_transformed_{datetime.now().strftime('%Y-%m-%d')}\",\"csv\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 67,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}